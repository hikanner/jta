# jsontrans - æŠ€æœ¯åˆ†ææ–‡æ¡£

> AI-powered JSON translation agent with terminology management

æœ¬æ–‡æ¡£åˆ†æäº†ä¸¤ç§ç¿»è¯‘ç³»ç»Ÿçš„æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼Œå¹¶è¿›è¡Œå¯¹æ¯”åˆ†æã€‚

---

## ğŸ“š ç›®å½•

1. [Andrew Ng çš„ Translation Agent åˆ†æ](#1-andrew-ng-çš„-translation-agent-åˆ†æ)
2. [å½“å‰å®ç°æ–¹æ¡ˆåˆ†æï¼ˆHiFlux Translation Toolï¼‰](#2-å½“å‰å®ç°æ–¹æ¡ˆåˆ†æhiflux-translation-tool)
3. [ä¸¤ç§æ–¹æ¡ˆå¯¹æ¯”](#3-ä¸¤ç§æ–¹æ¡ˆå¯¹æ¯”)
4. [æŠ€æœ¯é€‰å‹å»ºè®®](#4-æŠ€æœ¯é€‰å‹å»ºè®®)

---

## 1. Andrew Ng çš„ Translation Agent åˆ†æ

### 1.1 é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®**: [andrewyng/translation-agent](https://github.com/andrewyng/translation-agent)
**ä½œè€…**: Andrew Ng (deeplearning.ai åˆ›å§‹äºº)
**å‘å¸ƒæ—¶é—´**: 2024 å¹´ä¸­æœŸ
**Star æ•°**: 5.6k+

**æ ¸å¿ƒç†å¿µ**:
ä½¿ç”¨ **Agentic Workflowï¼ˆæ™ºèƒ½ä½“å·¥ä½œæµï¼‰** + **Reflectionï¼ˆåæ€æœºåˆ¶ï¼‰** å®ç°é«˜è´¨é‡ç¿»è¯‘ã€‚

---

### 1.2 æ ¸å¿ƒæ¶æ„

#### å·¥ä½œæµç¨‹ï¼šä¸‰æ­¥åæ€å¾ªç¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ç¿»è¯‘æµç¨‹                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  Step 1: Initial Translation (åˆå§‹ç¿»è¯‘)        â”‚
â”‚  â”œâ”€ ä½¿ç”¨ LLM ç›´æ¥ç¿»è¯‘æ–‡æœ¬                       â”‚
â”‚  â”œâ”€ Prompt: "ä½ æ˜¯ä¸“ä¸šç¿»è¯‘ï¼Œå°† X ç¿»è¯‘æˆ Y"       â”‚
â”‚  â””â”€ è¾“å‡º: translation_1                         â”‚
â”‚                                                 â”‚
â”‚           â†“                                     â”‚
â”‚                                                 â”‚
â”‚  Step 2: Reflection (åæ€è¯„ä»·)                 â”‚
â”‚  â”œâ”€ LLM æ‰®æ¼”ç¿»è¯‘è¯„è®ºå®¶                          â”‚
â”‚  â”œâ”€ å¯¹æ¯”åŸæ–‡å’Œåˆè¯‘                              â”‚
â”‚  â”œâ”€ ä» 4 ä¸ªç»´åº¦è¯„ä¼°:                            â”‚
â”‚  â”‚   â€¢ å‡†ç¡®æ€§ (Accuracy)                       â”‚
â”‚  â”‚   â€¢ æµç•…æ€§ (Fluency)                        â”‚
â”‚  â”‚   â€¢ é£æ ¼ (Style)                            â”‚
â”‚  â”‚   â€¢ æœ¯è¯­ (Terminology)                      â”‚
â”‚  â””â”€ è¾“å‡º: æ”¹è¿›å»ºè®®åˆ—è¡¨                          â”‚
â”‚                                                 â”‚
â”‚           â†“                                     â”‚
â”‚                                                 â”‚
â”‚  Step 3: Improved Translation (æ”¹è¿›ç¿»è¯‘)       â”‚
â”‚  â”œâ”€ ç»“åˆåŸæ–‡ã€åˆè¯‘ã€å»ºè®®                        â”‚
â”‚  â”œâ”€ LLM é‡æ–°ç¿»è¯‘                                â”‚
â”‚  â””â”€ è¾“å‡º: translation_2 (æœ€ç»ˆè¯‘æ–‡)             â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1.3 æ ¸å¿ƒä»£ç åˆ†æ

#### æ–‡ä»¶ç»“æ„

```
translation-agent/
â”œâ”€â”€ src/translation_agent/
â”‚   â”œâ”€â”€ __init__.py           # å¯¼å‡º translate å‡½æ•°
â”‚   â””â”€â”€ utils.py              # æ ¸å¿ƒé€»è¾‘ï¼ˆ678 è¡Œï¼‰
â””â”€â”€ examples/
    â””â”€â”€ example_script.py
```

**ä¸»è¦å‡½æ•°**ï¼š

```python
# ä¸»å…¥å£
translate(source_lang, target_lang, source_text, country, max_tokens=1000)

# å•å—ç¿»è¯‘ï¼ˆçŸ­æ–‡æœ¬ï¼‰
one_chunk_translate_text()
  â”œâ”€ one_chunk_initial_translation()    # åˆè¯‘
  â”œâ”€ one_chunk_reflect_on_translation() # åæ€
  â””â”€ one_chunk_improve_translation()    # æ”¹è¿›

# å¤šå—ç¿»è¯‘ï¼ˆé•¿æ–‡æœ¬ï¼‰
multichunk_translation()
  â”œâ”€ multichunk_initial_translation()
  â”œâ”€ multichunk_reflect_on_translation()
  â””â”€ multichunk_improve_translation()
```

---

#### æ ¸å¿ƒå®ç° 1: åˆå§‹ç¿»è¯‘

**å‡½æ•°**: `one_chunk_initial_translation()`

```python
def one_chunk_initial_translation(
    source_lang: str,
    target_lang: str,
    source_text: str
) -> str:
    """ç¬¬ä¸€æ­¥ï¼šç›´æ¥ç¿»è¯‘"""

    system_message = f"You are an expert linguist, specializing in translation from {source_lang} to {target_lang}."

    translation_prompt = f"""This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text.
Do not provide any explanations or text apart from the translation.

{source_lang}: {source_text}

{target_lang}:"""

    translation = get_completion(translation_prompt, system_message=system_message)

    return translation
```

**ç‰¹ç‚¹**ï¼š
- âœ… ç®€å•ç›´æ¥
- âœ… æ˜ç¡®è§’è‰²å®šä½ï¼ˆä¸“å®¶ç¿»è¯‘ï¼‰
- âŒ æ— æœ¯è¯­æŒ‡å¯¼
- âŒ æ— æ ¼å¼ä¿æŠ¤è¯´æ˜

---

#### æ ¸å¿ƒå®ç° 2: åæ€è¯„ä»·

**å‡½æ•°**: `one_chunk_reflect_on_translation()`

```python
def one_chunk_reflect_on_translation(
    source_lang: str,
    target_lang: str,
    source_text: str,
    translation_1: str,
    country: str = ""
) -> str:
    """ç¬¬äºŒæ­¥ï¼šåæ€å¹¶æå‡ºæ”¹è¿›å»ºè®®"""

    system_message = f"You are an expert linguist specializing in translation from {source_lang} to {target_lang}. You will be provided with a source text and its translation and your goal is to improve the translation."

    # å¦‚æœæŒ‡å®šäº†å›½å®¶/åœ°åŒº
    country_instruction = ""
    if country != "":
        country_instruction = f"The final style and tone of the translation should match the style of {target_lang} colloquially spoken in {country}."

    reflection_prompt = f"""Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticism and helpful suggestions to improve the translation.

{country_instruction}

The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

When writing suggestions, pay attention to whether there are ways to improve the translation's:
(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),
(iii) style (by ensuring the translations reflect the style of the source text and take into account any cultural context),
(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).

Write a list of specific, helpful and constructive suggestions for improving the translation.
Each suggestion should address one specific part of the translation.
Output only the suggestions and nothing else."""

    reflection = get_completion(reflection_prompt, system_message=system_message)

    return reflection
```

**å…³é”®è®¾è®¡**ï¼š
- âœ… **4 ç»´åº¦è¯„ä¼°**ï¼šå‡†ç¡®æ€§ã€æµç•…æ€§ã€é£æ ¼ã€æœ¯è¯­
- âœ… **åœ°åŒºåŒ–æ”¯æŒ**ï¼šå¯æŒ‡å®šå¦‚ "å¢¨è¥¿å“¥è¥¿ç­ç‰™è¯­"
- âœ… **å»ºè®¾æ€§æ‰¹è¯„**ï¼šè¦æ±‚å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®
- âœ… **XML æ ‡è®°**ï¼šæ¸…æ™°åˆ†éš”åŸæ–‡å’Œè¯‘æ–‡

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
å»ºè®®åˆ—è¡¨:
1. "Unleash" ç¿»è¯‘ä¸º "é‡Šæ”¾" è¾ƒç”Ÿç¡¬ï¼Œå»ºè®®æ”¹ä¸º "æ¿€å‘" æ›´è‡ªç„¶
2. è¯­åºè°ƒæ•´ï¼šå°† "ä½¿ç”¨ AI é©±åŠ¨çš„å›¾åƒç”Ÿæˆ" æ”¹ä¸º "ç”¨ AI å›¾åƒç”Ÿæˆ"
3. å¢åŠ æ„ŸæŸ“åŠ›ï¼šå¯ä»¥åŠ å¼ºè¯­æ°”ï¼Œå¦‚ "æ¿€å‘æ— é™åˆ›é€ åŠ›"
```

---

#### æ ¸å¿ƒå®ç° 3: æ”¹è¿›ç¿»è¯‘

**å‡½æ•°**: `one_chunk_improve_translation()`

```python
def one_chunk_improve_translation(
    source_lang: str,
    target_lang: str,
    source_text: str,
    translation_1: str,
    reflection: str
) -> str:
    """ç¬¬ä¸‰æ­¥ï¼šæ ¹æ®åæ€å»ºè®®æ”¹è¿›ç¿»è¯‘"""

    system_message = f"You are an expert linguist, specializing in translation editing from {source_lang} to {target_lang}."

    prompt = f"""Your task is to carefully read, then edit, a translation from {source_lang} to {target_lang}, taking into account a list of expert suggestions and constructive criticisms.

The source text, the initial translation, and the expert linguist suggestions are delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT>, <TRANSLATION></TRANSLATION> and <EXPERT_SUGGESTIONS></EXPERT_SUGGESTIONS> as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

<EXPERT_SUGGESTIONS>
{reflection}
</EXPERT_SUGGESTIONS>

Please take into account the expert suggestions when editing the translation.
Edit the translation by ensuring:
(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules and ensuring there are no unnecessary repetitions),
(iii) style (by ensuring the translations reflect the style of the source text)
(iv) terminology (inappropriate for context, inconsistent use), or
(v) other errors.

Output only the new translation and nothing else."""

    translation_2 = get_completion(prompt, system_message)

    return translation_2
```

**å…³é”®è®¾è®¡**ï¼š
- âœ… ç»¼åˆè€ƒè™‘ï¼šåŸæ–‡ + åˆè¯‘ + å»ºè®®
- âœ… æ˜ç¡®è§’è‰²ï¼šç¿»è¯‘ç¼–è¾‘ï¼ˆè€Œéåˆæ¬¡ç¿»è¯‘ï¼‰
- âœ… å¼ºè°ƒæ”¹è¿›ç‚¹ï¼š5 ä¸ªç»´åº¦çš„ä¼˜åŒ–
- âœ… çº¯è¾“å‡ºï¼šåªè¿”å›è¯‘æ–‡

---

#### æ ¸å¿ƒå®ç° 4: é•¿æ–‡æœ¬åˆ†å—

**é—®é¢˜**: LLM æœ‰ token é™åˆ¶ï¼Œé•¿æ–‡æœ¬æ— æ³•ä¸€æ¬¡ç¿»è¯‘ã€‚

**è§£å†³æ–¹æ¡ˆ**: æ™ºèƒ½åˆ†å— + ä¸Šä¸‹æ–‡ä¿æŒ

```python
def multichunk_initial_translation(
    source_lang: str,
    target_lang: str,
    source_text_chunks: List[str]
) -> List[str]:
    """ç¿»è¯‘å¤šä¸ªæ–‡æœ¬å—ï¼Œå…³é”®ï¼šæä¾›ä¸Šä¸‹æ–‡"""

    translation_chunks = []

    for i in range(len(source_text_chunks)):
        # æ ¸å¿ƒè®¾è®¡ï¼šç»™æ¯ä¸ªå—æä¾›å®Œæ•´ä¸Šä¸‹æ–‡
        tagged_text = (
            "".join(source_text_chunks[0:i])        # å‰æ–‡
            + "<TRANSLATE_THIS>"
            + source_text_chunks[i]                  # å½“å‰å—ï¼ˆéœ€ç¿»è¯‘ï¼‰
            + "</TRANSLATE_THIS>"
            + "".join(source_text_chunks[i + 1:])   # åæ–‡
        )

        prompt = f"""Your task is to provide a professional translation from {source_lang} to {target_lang} of PART of a text.

The source text is below, delimited by XML tags <SOURCE_TEXT> and </SOURCE_TEXT>.
Translate only the part within the source text delimited by <TRANSLATE_THIS> and </TRANSLATE_THIS>.
You can use the rest of the source text as context, but do not translate any of the other text.

<SOURCE_TEXT>
{tagged_text}
</SOURCE_TEXT>

To reiterate, you should translate only this part of the text:
<TRANSLATE_THIS>
{source_text_chunks[i]}
</TRANSLATE_THIS>

Output only the translation of the portion you are asked to translate, and nothing else."""

        translation = get_completion(prompt, system_message)
        translation_chunks.append(translation)

    return translation_chunks
```

**å…³é”®è®¾è®¡**ï¼š
- âœ… **ä¸Šä¸‹æ–‡ä¿æŒ**ï¼šè™½ç„¶åªç¿»è¯‘ä¸€éƒ¨åˆ†ï¼Œä½†ç»™å‡ºå®Œæ•´æ–‡æœ¬
- âœ… **æ˜ç¡®æ ‡è®°**ï¼šç”¨ `<TRANSLATE_THIS>` æ¸…æ™°æŒ‡ç¤ºç¿»è¯‘èŒƒå›´
- âœ… **è¿è´¯æ€§ä¿è¯**ï¼šLLM å¯ä»¥çœ‹åˆ°å‰åæ–‡ï¼Œä¿è¯ç¿»è¯‘è¿è´¯

**ç¤ºä¾‹**ï¼š
```
å‡è®¾æ–‡æœ¬åˆ†ä¸º 3 å—ï¼š[A, B, C]

ç¿»è¯‘ A æ—¶:
  ä¸Šä¸‹æ–‡: <TRANSLATE_THIS>A</TRANSLATE_THIS> B C

ç¿»è¯‘ B æ—¶:
  ä¸Šä¸‹æ–‡: A <TRANSLATE_THIS>B</TRANSLATE_THIS> C

ç¿»è¯‘ C æ—¶:
  ä¸Šä¸‹æ–‡: A B <TRANSLATE_THIS>C</TRANSLATE_THIS>
```

---

#### æ ¸å¿ƒå®ç° 5: æ™ºèƒ½åˆ†å—ç®—æ³•

**å‡½æ•°**: `calculate_chunk_size()`

```python
def calculate_chunk_size(token_count: int, token_limit: int) -> int:
    """
    æ™ºèƒ½è®¡ç®—åˆ†å—å¤§å°

    ç›®æ ‡: åœ¨ token é™åˆ¶å†…ï¼Œæœ€å°åŒ–å—æ•°é‡

    ç®—æ³•:
    1. å¦‚æœæ€» token <= é™åˆ¶ï¼Œä¸åˆ†å—
    2. å¦åˆ™ï¼Œè®¡ç®—éœ€è¦çš„å—æ•°
    3. å¹³å‡åˆ†é… token åˆ°æ¯ä¸ªå—
    4. è€ƒè™‘ä½™æ•°ï¼Œé¿å…æœ€åä¸€å—è¿‡å°
    """

    if token_count <= token_limit:
        return token_count

    # è®¡ç®—éœ€è¦çš„å—æ•°ï¼ˆå‘ä¸Šå–æ•´ï¼‰
    num_chunks = (token_count + token_limit - 1) // token_limit

    # å¹³å‡æ¯å—å¤§å°
    chunk_size = token_count // num_chunks

    # åˆ†é…ä½™æ•°
    remaining_tokens = token_count % token_limit
    if remaining_tokens > 0:
        chunk_size += remaining_tokens // num_chunks

    return chunk_size
```

**ç¤ºä¾‹**ï¼š
```python
>>> calculate_chunk_size(1000, 500)
500  # åˆšå¥½ 2 å—

>>> calculate_chunk_size(1530, 500)
389  # 4 å—ï¼Œæ¯å—çº¦ 389 token

>>> calculate_chunk_size(2242, 500)
496  # 5 å—ï¼Œæ¯å—çº¦ 496 token
```

**ä¼˜ç‚¹**ï¼š
- âœ… å—å¤§å°å‡è¡¡
- âœ… é¿å…è¿‡å°çš„æœ€åä¸€å—
- âœ… æœ€å°åŒ–å—æ•°é‡

---

### 1.4 ä¼˜åŠ¿åˆ†æ

#### âœ… ä¼˜åŠ¿

1. **ç¿»è¯‘è´¨é‡é«˜**
   - é€šè¿‡åæ€æœºåˆ¶è‡ªæˆ‘æ”¹è¿›
   - å¤šè½®è¿­ä»£ä¼˜åŒ–
   - é€‚åˆé«˜è´¨é‡æ–‡æ¡£ç¿»è¯‘

2. **æ–‡åŒ–é€‚é…å¥½**
   - æ”¯æŒåœ°åŒºæ–¹è¨€ï¼ˆå¦‚å¢¨è¥¿å“¥è¥¿ç­ç‰™è¯­ï¼‰
   - é£æ ¼è‡ªç„¶æµç•…
   - è€ƒè™‘æ–‡åŒ–èƒŒæ™¯

3. **å®ç°ç®€æ´**
   - ä»£ç ç®€å•æ˜“æ‡‚ï¼ˆ678 è¡Œï¼‰
   - é€»è¾‘æ¸…æ™°
   - æ˜“äºæ‰©å±•

4. **é•¿æ–‡æœ¬å¤„ç†å¥½**
   - æ™ºèƒ½åˆ†å—
   - ä¿æŒä¸Šä¸‹æ–‡
   - ç¿»è¯‘è¿è´¯

---

#### âŒ åŠ£åŠ¿

1. **æˆæœ¬é«˜**
   - 3 å€ API è°ƒç”¨ï¼ˆåˆè¯‘ + åæ€ + æ”¹è¿›ï¼‰
   - é€‚åˆé¢„ç®—å……è¶³çš„åœºæ™¯

2. **é€Ÿåº¦æ…¢**
   - 3 å€è€—æ—¶
   - ä¸é€‚åˆå®æ—¶ç¿»è¯‘

3. **æ— æœ¯è¯­ç®¡ç†**
   - ä¾èµ– LLM è‡ªè¡Œç†è§£æœ¯è¯­
   - æœ¯è¯­ä¸€è‡´æ€§æ— æ³•å¼ºåˆ¶ä¿è¯

4. **æ— æ ¼å¼ä¿æŠ¤**
   - æœªç‰¹åˆ«å¤„ç†å ä½ç¬¦ã€HTML ç­‰
   - å®¹æ˜“æŸåæ ¼å¼

5. **æ— å¹¶å‘å¤„ç†**
   - åŒæ­¥é¡ºåºå¤„ç†
   - æ•ˆç‡è¾ƒä½

6. **æ— å¢é‡ç¿»è¯‘**
   - æ¯æ¬¡éƒ½é‡æ–°ç¿»è¯‘æ•´ä¸ªæ–‡ä»¶
   - æ— ç¼“å­˜æœºåˆ¶

---

### 1.5 é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**ï¼š
- é«˜è´¨é‡æ–‡æ¡£ç¿»è¯‘ï¼ˆç™½çš®ä¹¦ã€æŠ€æœ¯æ–‡æ¡£ï¼‰
- è¥é”€æ–‡æ¡ˆï¼ˆå¹¿å‘Šã€å“ç‰Œä»‹ç»ï¼‰
- æ–‡å­¦ä½œå“
- éœ€è¦æ–‡åŒ–é€‚é…çš„å†…å®¹
- é¢„ç®—å……è¶³çš„é¡¹ç›®

âŒ **ä¸é€‚åˆ**ï¼š
- å¤§è§„æ¨¡æ‰¹é‡ç¿»è¯‘
- å®æ—¶ç¿»è¯‘
- éœ€è¦æœ¯è¯­å¼ºä¸€è‡´æ€§çš„åœºæ™¯
- JSON/ä»£ç å›½é™…åŒ–
- é¢„ç®—æœ‰é™çš„é¡¹ç›®

---

## 2. å½“å‰å®ç°æ–¹æ¡ˆåˆ†æï¼ˆHiFlux Translation Toolï¼‰

### 2.1 é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®**: translate-json
**ç”¨é€”**: HiFlux AI å›¾åƒç”Ÿæˆå¹³å°çš„å¤šè¯­è¨€ç¿»è¯‘å·¥å…·
**æ”¯æŒè¯­è¨€**: 26 ç§
**æ ¸å¿ƒæ¨¡å‹**: AWS Bedrock Claude Sonnet 4

---

### 2.2 æ ¸å¿ƒæ¶æ„

#### å·¥ä½œæµç¨‹ï¼šæ‰¹é‡å¹¶å‘ + æœ¯è¯­ç®¡ç†

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ç¿»è¯‘æµç¨‹                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Step 1: æºæ–‡ä»¶åˆ†æ                              â”‚
â”‚  â”œâ”€ åŠ è½½ en.json                                 â”‚
â”‚  â”œâ”€ é€’å½’æå–æ‰€æœ‰å¯ç¿»è¯‘æ–‡æœ¬                        â”‚
â”‚  â”œâ”€ åˆ†ææ··åˆæ ¼å¼ï¼ˆå ä½ç¬¦å†…å¤–ï¼‰                    â”‚
â”‚  â””â”€ æå–æœ¯è¯­                                     â”‚
â”‚                                                  â”‚
â”‚           â†“                                      â”‚
â”‚                                                  â”‚
â”‚  Step 2: æœ¯è¯­æ˜ å°„                                â”‚
â”‚  â”œâ”€ åŠ è½½ terminology.json                        â”‚
â”‚  â”œâ”€ åŒ¹é…æœ¯è¯­ç¿»è¯‘                                 â”‚
â”‚  â”œâ”€ è¯†åˆ«ä¿ç•™æœ¯è¯­                                 â”‚
â”‚  â””â”€ æ„å»ºæœ¯è¯­è¯å…¸                                 â”‚
â”‚                                                  â”‚
â”‚           â†“                                      â”‚
â”‚                                                  â”‚
â”‚  Step 3: æ‰¹é‡ç¿»è¯‘                                â”‚
â”‚  â”œâ”€ åˆ›å»ºæ™ºèƒ½æ‰¹æ¬¡ï¼ˆæŒ‰ä¸Šä¸‹æ–‡åˆ†ç»„ï¼‰                  â”‚
â”‚  â”œâ”€ å¹¶å‘å¤„ç†æ‰¹æ¬¡ï¼ˆasyncioï¼‰                      â”‚
â”‚  â”‚   â”œâ”€ æ‰¹æ¬¡ 1 â†’ API è°ƒç”¨ â”                     â”‚
â”‚  â”‚   â”œâ”€ æ‰¹æ¬¡ 2 â†’ API è°ƒç”¨ â”œâ”€ å¹¶å‘ï¼ˆ3ä¸ªï¼‰         â”‚
â”‚  â”‚   â””â”€ æ‰¹æ¬¡ 3 â†’ API è°ƒç”¨ â”˜                     â”‚
â”‚  â”œâ”€ å¤±è´¥é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰                         â”‚
â”‚  â””â”€ é™çº§å¤„ç†ï¼ˆæ‰¹é‡â†’å•ä¸ªï¼‰                        â”‚
â”‚                                                  â”‚
â”‚           â†“                                      â”‚
â”‚                                                  â”‚
â”‚  Step 4: åå¤„ç†                                  â”‚
â”‚  â”œâ”€ æ’ç‰ˆè§„èŒƒåŒ–                                   â”‚
â”‚  â”‚   â€¢ ä¸­æ–‡ï¼šä¸­è‹±æ–‡é—´åŠ ç©ºæ ¼                      â”‚
â”‚  â”‚   â€¢ æ³•è¯­ï¼šå†’å·å‰åŠ ç©ºæ ¼                        â”‚
â”‚  â”œâ”€ RTL å¤„ç†ï¼ˆå¦‚é˜¿æ‹‰ä¼¯è¯­ï¼‰                       â”‚
â”‚  â”‚   â€¢ æ·»åŠ æ–¹å‘æ ‡è®°                              â”‚
â”‚  â”‚   â€¢ æ•°å­—è½¬æ¢                                  â”‚
â”‚  â””â”€ é‡å»º JSON ç»“æ„                               â”‚
â”‚                                                  â”‚
â”‚           â†“                                      â”‚
â”‚                                                  â”‚
â”‚  Step 5: è´¨é‡éªŒè¯                                â”‚
â”‚  â”œâ”€ JSON ç»“æ„å®Œæ•´æ€§                              â”‚
â”‚  â”œâ”€ æœ¯è¯­ä¸€è‡´æ€§                                   â”‚
â”‚  â”œâ”€ å ä½ç¬¦å®Œæ•´æ€§                                 â”‚
â”‚  â””â”€ ç”ŸæˆéªŒè¯æŠ¥å‘Š                                 â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2.3 æ ¸å¿ƒä»£ç åˆ†æ

#### æ–‡ä»¶ç»“æ„

```
translate-json/
â”œâ”€â”€ translate.py                # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ config.py                   # é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ core/                       # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ translator.py           # ç¿»è¯‘å¼•æ“ï¼ˆ567 è¡Œï¼‰
â”‚   â”œâ”€â”€ terminology_manager.py  # æœ¯è¯­ç®¡ç†ï¼ˆ341 è¡Œï¼‰
â”‚   â”œâ”€â”€ validator.py            # è´¨é‡éªŒè¯
â”‚   â”œâ”€â”€ rtl_processor.py        # RTL å¤„ç†
â”‚   â”œâ”€â”€ typography_processor.py # æ’ç‰ˆå¤„ç†
â”‚   â””â”€â”€ interactive.py          # äº¤äº’ç•Œé¢
â”‚
â”œâ”€â”€ utils/                      # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ bedrock_client.py       # AWS Bedrock å®¢æˆ·ç«¯
â”‚   â””â”€â”€ file_handler.py         # æ–‡ä»¶å¤„ç†
â”‚
â”œâ”€â”€ prompts/                    # æç¤ºè¯æ¨¡æ¿
â”‚   â””â”€â”€ translation_prompts.py  # ç¿»è¯‘æç¤ºè¯ï¼ˆ237 è¡Œï¼‰
â”‚
â””â”€â”€ data/                       # æ•°æ®æ–‡ä»¶
    â”œâ”€â”€ languages.json          # æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
    â””â”€â”€ terminology.json        # æœ¯è¯­è¯å…¸
```

---

### 2.4 æ ¸å¿ƒå®ç°

#### æ ¸å¿ƒå®ç° 1: æœ¯è¯­ç®¡ç†ç³»ç»Ÿ

**æ–‡ä»¶**: `core/terminology_manager.py`

**æœ¯è¯­é…ç½®** - `data/terminology.json`:
```json
{
  "preserve_terms": [
    "HiFlux AI",
    "FLUX.1",
    "API",
    "OAuth"
  ],
  "consistent_terms": {
    "zh": {
      "credits": "ç‚¹æ•°",
      "generation": "ç”Ÿæˆ",
      "premium": "é«˜çº§ç‰ˆ",
      "model": "æ¨¡å‹",
      "background remover": "èƒŒæ™¯ç§»é™¤å™¨",
      "watermark remover": "æ°´å°ç§»é™¤å™¨"
    },
    "ja": {
      "credits": "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ",
      "generation": "ç”Ÿæˆ",
      "premium": "ãƒ—ãƒ¬ãƒŸã‚¢ãƒ "
    }
  },
  "context_patterns": {
    "pricing": ["price", "plan", "credit", "payment"],
    "generation": ["generate", "create", "model"],
    "settings": ["setting", "config", "preference"]
  }
}
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **æœ¯è¯­æå–**
```python
def extract_terms_from_text(self, text: str) -> Set[str]:
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®æœ¯è¯­"""

    terms = set()

    # 1. ä¼˜å…ˆæ£€æŸ¥ä¿ç•™æœ¯è¯­ï¼ˆæœ€é•¿åŒ¹é…ï¼‰
    for preserve_term in sorted(self.preserve_terms, key=len, reverse=True):
        if preserve_term in text:
            terms.add(preserve_term)

    # 2. æå–å·²çŸ¥çš„ä¸€è‡´æ€§æœ¯è¯­
    for term in self.get_known_terms():
        if self.find_term_in_text(text, term):
            terms.add(term)

    # 3. æå–ä¸“ä¸šæœ¯è¯­æ¨¡å¼
    # é¦–å­—æ¯å¤§å†™çš„å•è¯
    capitalized_words = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
    terms.update(capitalized_words)

    # è¿å­—ç¬¦æœ¯è¯­
    hyphenated_terms = re.findall(r'\b\w+(?:-\w+)+\b', text)
    terms.update(hyphenated_terms)

    # æŠ€æœ¯ç¼©å†™
    acronyms = re.findall(r'\b[A-Z]{2,}\b', text)
    terms.update(acronyms)

    return terms
```

2. **æœ¯è¯­å¼ºåˆ¶åº”ç”¨**
```python
def build_term_dictionary_for_prompt(self, target_lang: str, terms_in_text: List[str]) -> str:
    """ä¸º Prompt æ„å»ºæœ¯è¯­è¯å…¸"""

    preserve_entries = []
    translate_entries = []

    # æ”¶é›†ä¿ç•™æœ¯è¯­
    for preserve_term in self.preserve_terms:
        preserve_entries.append(f'"{preserve_term}" â†’ NEVER TRANSLATE, KEEP EXACTLY AS IS')

    # æ”¶é›†ç¿»è¯‘æœ¯è¯­
    for term in terms_in_text:
        translation = self.get_term_translation(term, target_lang)
        if translation != term:
            translate_entries.append(f'"{term}" â†’ "{translation}"')

    result_lines = []

    # ä¿ç•™æœ¯è¯­ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    if preserve_entries:
        result_lines.append("âš ï¸  CRITICAL - NEVER TRANSLATE THESE TERMS:")
        result_lines.extend([f"   {entry}" for entry in preserve_entries])

    # ä¸€è‡´æ€§ç¿»è¯‘æœ¯è¯­
    if translate_entries:
        result_lines.append("ğŸ“ REQUIRED TRANSLATIONS:")
        result_lines.extend([f"   {entry}" for entry in translate_entries])

    result_lines.append("ğŸ¯ INSTRUCTION: Follow these translations EXACTLY.")

    return "\n".join(result_lines)
```

**è¾“å‡ºç¤ºä¾‹**ï¼ˆæ³¨å…¥åˆ° Promptï¼‰ï¼š
```
âš ï¸  CRITICAL - NEVER TRANSLATE THESE TERMS:
   "HiFlux AI" â†’ NEVER TRANSLATE, KEEP EXACTLY AS IS
   "FLUX.1" â†’ NEVER TRANSLATE, KEEP EXACTLY AS IS

ğŸ“ REQUIRED TRANSLATIONS:
   "credits" â†’ "ç‚¹æ•°"
   "generation" â†’ "ç”Ÿæˆ"
   "premium" â†’ "é«˜çº§ç‰ˆ"

ğŸ¯ INSTRUCTION: Follow these translations EXACTLY.
```

---

#### æ ¸å¿ƒå®ç° 2: æ··åˆæ ¼å¼æ™ºèƒ½å¤„ç†

**é—®é¢˜**: JSON ä¸­å¸¸è§æ··åˆæ ¼å¼ï¼Œå¦‚ `"{credits} credits {label}"`
- å ä½ç¬¦ `{credits}` å’Œ `{label}` ä¸èƒ½ç¿»è¯‘
- ä¸­é—´çš„ "credits" éœ€è¦ç¿»è¯‘ä¸º "ç‚¹æ•°"

**è§£å†³æ–¹æ¡ˆ**: æ™ºèƒ½åˆ†æå ä½ç¬¦å†…å¤–å†…å®¹

```python
def analyze_mixed_format_text(self, text: str) -> Dict[str, Any]:
    """åˆ†ææ··åˆæ ¼å¼æ–‡æœ¬ï¼ŒåŒºåˆ†å ä½ç¬¦å†…å¤–çš„å†…å®¹"""

    # 1. æå–æ‰€æœ‰å ä½ç¬¦
    placeholders = re.findall(r'\{[^}]+\}', text)

    # 2. åˆ†ç¦»å ä½ç¬¦å¤–çš„æ–‡æœ¬
    outside_text = text
    placeholder_map = {}

    # ç”¨ä¸´æ—¶æ ‡è®°æ›¿æ¢å ä½ç¬¦ï¼Œä¿æŒä½ç½®ä¿¡æ¯
    for i, placeholder in enumerate(placeholders):
        temp_marker = f" __PLACEHOLDER_{i}__ "
        placeholder_map[temp_marker] = placeholder
        outside_text = outside_text.replace(placeholder, temp_marker)

    # 3. æ¸…ç†å¹¶æå–å ä½ç¬¦å¤–çš„çº¯æ–‡æœ¬
    outside_content = outside_text
    for marker in placeholder_map.keys():
        outside_content = outside_content.replace(marker, ' ')
    outside_content = ' '.join(outside_content.split()).strip()

    # 4. æ£€æŸ¥å ä½ç¬¦å¤–çš„å†…å®¹æ˜¯å¦éœ€è¦ç¿»è¯‘
    needs_translation = (
        len(outside_content) > 0 and
        any(c.isalpha() and ord(c) < 128 for c in outside_content) and
        not outside_content.isdigit()
    )

    # 5. è¯†åˆ«å ä½ç¬¦å¤–çš„è‹±æ–‡æœ¯è¯­
    outside_terms = []
    if needs_translation:
        words = re.findall(r'\b[a-zA-Z]+\b', outside_content)
        for word in words:
            if len(word) > 1:
                outside_terms.append(word.lower())

    return {
        'has_placeholders': len(placeholders) > 0,
        'placeholders': placeholders,
        'placeholder_map': placeholder_map,
        'outside_content': outside_content,
        'outside_terms': outside_terms,  # åªæå–å ä½ç¬¦å¤–çš„æœ¯è¯­
        'needs_translation': needs_translation,
        'translation_type': self._determine_translation_type(placeholders, outside_content),
        'processed_template': outside_text
    }
```

**ç¤ºä¾‹**ï¼š
```python
text = "{credits} credits {label}"

analysis = analyze_mixed_format_text(text)

# ç»“æœï¼š
{
    'has_placeholders': True,
    'placeholders': ['{credits}', '{label}'],
    'outside_content': 'credits',        # åªæœ‰è¿™ä¸ªéœ€è¦ç¿»è¯‘
    'outside_terms': ['credits'],        # æœ¯è¯­æå–
    'needs_translation': True,
    'translation_type': 'mixed',
    'processed_template': ' __PLACEHOLDER_0__  credits  __PLACEHOLDER_1__ '
}

# Prompt ä¸­ä¼šæ˜ç¡®è¯´æ˜ï¼š
# "åªç¿»è¯‘å ä½ç¬¦å¤–çš„ 'credits'ï¼Œä¿æŒ {credits} å’Œ {label} ä¸å˜"

# ç¿»è¯‘ç»“æœï¼š
# "{credits} ç‚¹æ•° {label}"
```

---

#### æ ¸å¿ƒå®ç° 3: æ‰¹é‡å¹¶å‘ç¿»è¯‘

**æ–‡ä»¶**: `core/translator.py`

**æ™ºèƒ½æ‰¹æ¬¡åˆ›å»º**ï¼š
```python
def create_translation_batches(self, translatable_items: List[Dict]) -> List[List[Dict]]:
    """åˆ›å»ºæ™ºèƒ½ç¿»è¯‘æ‰¹æ¬¡"""

    batches = []
    current_batch = []
    current_batch_chars = 0

    # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œå­—ç¬¦é™åˆ¶
    max_chars_per_batch = min(4000, max(2000, self.batch_size * 150))

    # æŒ‰ä¸Šä¸‹æ–‡åˆ†ç»„ä¼˜åŒ–
    context_groups = {}
    for item in translatable_items:
        context = item.get('context', 'general')
        if context not in context_groups:
            context_groups[context] = []
        context_groups[context].append(item)

    # ä¼˜å…ˆå¤„ç†åŒä¸€ä¸Šä¸‹æ–‡çš„é¡¹ç›®
    for context, items in context_groups.items():
        for item in items:
            chars_needed = item['char_count']

            # æ™ºèƒ½æ‰¹æ¬¡åˆ‡åˆ†
            should_create_new_batch = (
                current_batch and (
                    len(current_batch) >= self.batch_size or
                    current_batch_chars + chars_needed > max_chars_per_batch or
                    # ä¸Šä¸‹æ–‡åˆ‡æ¢æ—¶è€ƒè™‘åˆ›å»ºæ–°æ‰¹æ¬¡
                    (len(current_batch) > self.batch_size // 2 and
                     current_batch[-1].get('context') != item.get('context'))
                )
            )

            if should_create_new_batch:
                batches.append(current_batch)
                current_batch = []
                current_batch_chars = 0

            current_batch.append(item)
            current_batch_chars += chars_needed

    # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
    if current_batch:
        batches.append(current_batch)

    return batches
```

**å¹¶å‘å¤„ç† + é™çº§æœºåˆ¶**ï¼š
```python
async def process_translation_batches(
    self,
    batches: List[List[Dict]],
    target_lang: str,
    terminology_dict: str
) -> Dict[str, str]:
    """å¹¶å‘å¤„ç†ç¿»è¯‘æ‰¹æ¬¡"""

    translated_items = {}

    async def process_batch(batch_index: int, batch: List[Dict]) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡ï¼ŒåŒ…å«é‡è¯•å’Œé™çº§æœºåˆ¶"""

        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            batch_results = {}
            retry_count = 0
            max_retries = 3

            while retry_count <= max_retries:
                try:
                    # è°ƒç”¨æ‰¹é‡ç¿»è¯‘
                    translated_batch = await self.bedrock_client.translate_batch(
                        batch, target_lang, terminology_dict
                    )

                    # æ”¶é›†ç»“æœ
                    for item in translated_batch:
                        path = item['path']
                        translated_text = item.get('translated_text', item['text'])
                        batch_results[path] = translated_text

                    # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯
                    break

                except Exception as e:
                    retry_count += 1

                    if retry_count <= max_retries:
                        # æŒ‡æ•°é€€é¿ç­–ç•¥
                        wait_time = min(30, 2 ** retry_count * RATE_LIMIT_DELAY)
                        await asyncio.sleep(wait_time)

                        # å¦‚æœæ˜¯æ‰¹æ¬¡è¿‡å¤§é—®é¢˜ï¼Œå°è¯•åˆ†å‰²æ‰¹æ¬¡
                        if "too large" in str(e).lower():
                            if len(batch) > 1:
                                # åˆ†å‰²æ‰¹æ¬¡å¹¶é€’å½’å¤„ç†
                                mid = len(batch) // 2
                                sub_batch1 = batch[:mid]
                                sub_batch2 = batch[mid:]

                                result1 = await self.process_single_batch_with_fallback(
                                    sub_batch1, target_lang, terminology_dict
                                )
                                result2 = await self.process_single_batch_with_fallback(
                                    sub_batch2, target_lang, terminology_dict
                                )

                                batch_results.update(result1)
                                batch_results.update(result2)
                                break
                    else:
                        # æœ€ç»ˆå¤±è´¥ï¼Œé™çº§åˆ°å•ä¸ªç¿»è¯‘
                        batch_results = await self.fallback_to_single_translation(
                            batch, target_lang, terminology_dict
                        )

            # æ›´æ–°å…¨å±€ç»“æœ
            translated_items.update(batch_results)

            return {
                'batch_index': batch_index,
                'success': len(batch_results) > 0,
                'retry_count': retry_count,
                'items_processed': len(batch_results)
            }

    # åˆ›å»ºæ‰€æœ‰æ‰¹æ¬¡ä»»åŠ¡
    tasks = [
        process_batch(i, batch)
        for i, batch in enumerate(batches)
    ]

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡
    batch_results = await asyncio.gather(*tasks, return_exceptions=True)

    return translated_items
```

**é™çº§ç­–ç•¥**ï¼š
```
æ‰¹é‡ç¿»è¯‘å¤±è´¥
    â†“
é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    â†“
åˆ†å‰²æ‰¹æ¬¡
    â†“
å•ä¸ªç¿»è¯‘
    â†“
ä¿ç•™åŸæ–‡ï¼ˆæœ€ç»ˆé™çº§ï¼‰
```

---

#### æ ¸å¿ƒå®ç° 4: é«˜çº§ Prompt è®¾è®¡

**æ–‡ä»¶**: `prompts/translation_prompts.py`

**è¯­è¨€ç‰¹å®šé…ç½®**ï¼š
```python
configs = {
    'zh': {
        'name': 'ç®€ä½“ä¸­æ–‡',
        'typography_rules': [
            'ä¸­æ–‡ä¸è‹±æ–‡ä¹‹é—´å¿…é¡»åŠ ç©ºæ ¼ï¼ˆå¦‚ï¼šHiFlux AI æ˜¯ä¸€ä¸ªå¹³å°ï¼‰',
            'ä¸­æ–‡ä¸æ•°å­—ä¹‹é—´å¿…é¡»åŠ ç©ºæ ¼ï¼ˆå¦‚ï¼šèŠ‚çœ 20% è´¹ç”¨ï¼‰',
            'æ•°å­—ä¸å•ä½ä¹‹é—´åŠ ç©ºæ ¼ï¼ˆå¦‚ï¼šçº¦ 6 ç§’ã€10 å€ï¼‰',
            'è‹±æ–‡ä¸“æœ‰åè¯å‰ååŠ ç©ºæ ¼ï¼ˆå¦‚ï¼šä½¿ç”¨ FLUX.1 æ¨¡å‹ï¼‰',
            'å˜é‡å ä½ç¬¦ç´§è´´ä¸­æ–‡ï¼ˆå¦‚ï¼š{count}ä¸ªé¡¹ç›®ï¼‰',
            'ä¸­æ–‡æ ‡ç‚¹ç¬¦å·å‰åä¸åŠ ç©ºæ ¼'
        ],
        'style_guide': [
            'ä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œé¿å…ç¹ä½“å­—',
            'æœ¯è¯­ä¿æŒä¸€è‡´æ€§ï¼Œä½¿ç”¨å·²å»ºç«‹çš„æœ¯è¯­æ˜ å°„',
            'è¯­è°ƒè‡ªç„¶å‹å¥½ï¼Œç¬¦åˆäº§å“è°ƒæ€§',
            'æŠ€æœ¯è¯æ±‡å‡†ç¡®ï¼Œé¿å…ç”Ÿç¡¬ç¿»è¯‘'
        ]
    }
}
```

**æ‰¹é‡ç¿»è¯‘ Prompt**ï¼š
```python
def build_batch_translation_prompt(texts: list, target_lang: str,
                                 terminology_dict: str = "") -> str:
    """æ„å»ºæ‰¹é‡ç¿»è¯‘æç¤ºè¯"""

    config = TranslationPrompts.get_language_config(target_lang)
    lang_name = config['name']
    typography_rules = config['typography_rules']
    style_guide = config['style_guide']

    # æ„å»ºæ’ç‰ˆè§„èŒƒæ–‡æœ¬
    typography_text = "\n".join([f"â€¢ {rule}" for rule in typography_rules])
    style_text = "\n".join([f"â€¢ {rule}" for rule in style_guide])

    # æ„å»ºæ–‡æœ¬åˆ—è¡¨
    text_list = ""
    for i, item in enumerate(texts):
        item_id = i + 1
        text_list += f"[{item_id}] {item['text']}\n"

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æœ¬åœ°åŒ–ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿UI/UXæ–‡æ¡ˆçš„æ‰¹é‡ç¿»è¯‘ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬æ‰¹é‡ç¿»è¯‘æˆ{lang_name}ã€‚

ã€é¡¹ç›®èƒŒæ™¯ã€‘
è¿™æ˜¯HiFlux AIå›¾åƒç”Ÿæˆå¹³å°çš„ç”¨æˆ·ç•Œé¢æ–‡æ¡ˆï¼Œéœ€è¦ä¿æŒä¸€è‡´çš„ç¿»è¯‘é£æ ¼å’Œæœ¯è¯­ä½¿ç”¨ã€‚

ã€æœ¯è¯­è¯å…¸ã€‘
{terminology_dict if terminology_dict else "éµå¾ªäº§å“æœ¯è¯­è§„èŒƒ"}

ã€æ’ç‰ˆè§„èŒƒã€‘
{typography_text}

ã€ç¿»è¯‘é£æ ¼æŒ‡å—ã€‘
{style_text}

ã€æ ¸å¿ƒè¦æ±‚ã€‘
1. ğŸ”’ ä¸¥æ ¼ä¿æŒæ‰€æœ‰å˜é‡å ä½ç¬¦ä¸å˜ï¼ˆå¦‚ï¼š{{variable}}ã€{{count}}ç­‰ï¼‰
2. ğŸ·ï¸ ä¸¥æ ¼ä¿æŒæ‰€æœ‰HTMLæ ‡ç­¾å’Œç‰¹æ®Šæ ‡è®°ä¸å˜ï¼ˆå¦‚ï¼š[highlight]ã€[/highlight]ï¼‰
3. ğŸ“ ä¸¥æ ¼éµå¾ªæ’ç‰ˆè§„èŒƒï¼Œç‰¹åˆ«æ³¨æ„ç©ºæ ¼ä½¿ç”¨
4. ğŸ¯ ä¿æŒæœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§
5. âš¡ æŒ‰ç…§ [ID] ç¿»è¯‘ç»“æœ çš„æ ¼å¼è¿”å›ï¼Œä¸è¦å…¶ä»–è¯´æ˜
6. ğŸ”„ ç¡®ä¿ä¸Šä¸‹æ–‡ç›¸å…³çš„æ–‡æ¡ˆä¿æŒé€»è¾‘ä¸€è‡´æ€§

ã€æ··åˆæ ¼å¼ç‰¹åˆ«è¯´æ˜ã€‘
å¯¹äºåŒ…å«å˜é‡å ä½ç¬¦çš„æ··åˆæ ¼å¼æ–‡æœ¬ï¼ˆå¦‚ï¼š{{{{credits}}}} credits {{{{label}}}}ï¼‰ï¼Œè¯·æ³¨æ„ï¼š
â€¢ å˜é‡å ä½ç¬¦{{{{...}}}}å†…çš„å†…å®¹ç»å¯¹ä¸èƒ½ç¿»è¯‘
â€¢ å ä½ç¬¦å¤–çš„æ™®é€šè‹±æ–‡å•è¯éœ€è¦ç¿»è¯‘
â€¢ ä¿æŒå ä½ç¬¦çš„ä½ç½®å’Œæ ¼å¼ä¸å˜
â€¢ ç¤ºä¾‹ï¼š{{{{credits}}}} credits {{{{label}}}} â†’ {{{{credits}}}} ç‚¹æ•° {{{{label}}}}

ã€å¾…ç¿»è¯‘æ–‡æœ¬ã€‘
{text_list}

ã€ç¿»è¯‘ç»“æœã€‘"""

    return prompt
```

**å…³é”®è®¾è®¡**ï¼š
- âœ… **å¤šå±‚æ¬¡æŒ‡å¯¼**ï¼šèƒŒæ™¯ + æœ¯è¯­ + æ’ç‰ˆ + é£æ ¼
- âœ… **ç‰¹æ®Šè¯´æ˜**ï¼šæ··åˆæ ¼å¼çš„è¯¦ç»†å¤„ç†è§„åˆ™
- âœ… **æ‰¹é‡æ ¼å¼**ï¼š`[ID] ç¿»è¯‘ç»“æœ` æ¸…æ™°ç»“æ„åŒ–
- âœ… **å¼ºè°ƒå…³é”®ç‚¹**ï¼šç”¨ emoji çªå‡ºé‡è¦è§„åˆ™

---

#### æ ¸å¿ƒå®ç° 5: RTL è¯­è¨€å¤„ç†

**æ–‡ä»¶**: `core/rtl_processor.py`

```python
class RTLProcessor:
    """RTLï¼ˆä»å³åˆ°å·¦ï¼‰è¯­è¨€å¤„ç†å™¨"""

    def process_rtl_json(self, data: Dict, target_lang: str, lang_info: Dict) -> Dict:
        """å¤„ç† RTL è¯­è¨€çš„ç‰¹æ®Šéœ€æ±‚"""

        # 1. æ·»åŠ æ–¹å‘æ ‡è®°
        data = self.add_direction_marks(data, lang_info)

        # 2. æ•°å­—è½¬æ¢ï¼ˆå¯é€‰ï¼‰
        if self.should_convert_numbers(target_lang):
            data = self.convert_numbers_to_local(data, target_lang)

        # 3. æ ‡ç‚¹ç¬¦å·è½¬æ¢
        data = self.convert_punctuation(data, target_lang)

        return data

    def add_direction_marks(self, data: Any, lang_info: Dict) -> Any:
        """ä¸ºè‹±æ–‡æœ¯è¯­æ·»åŠ æ–¹å‘æ ‡è®°"""

        preserve_terms = self.get_preserve_terms()

        def add_marks_to_text(text: str) -> str:
            """ä¸ºæ–‡æœ¬ä¸­çš„è‹±æ–‡æœ¯è¯­æ·»åŠ  LTR æ ‡è®°"""

            for term in preserve_terms:
                # æ£€æŸ¥æœ¯è¯­æ˜¯å¦å­˜åœ¨
                if term in text:
                    # æ·»åŠ  LTR æ ‡è®°ï¼šâ€termâ€
                    marked_term = f"â€{term}â€"
                    text = text.replace(term, marked_term)

            return text

        # é€’å½’å¤„ç† JSON
        return self._process_recursive(data, add_marks_to_text)

    def convert_numbers_to_local(self, data: Any, target_lang: str) -> Any:
        """è½¬æ¢æ•°å­—ä¸ºæœ¬åœ°æ ¼å¼"""

        # é˜¿æ‹‰ä¼¯è¯­æ•°å­—æ˜ å°„
        arabic_digits = {
            '0': 'Ù ', '1': 'Ù¡', '2': 'Ù¢', '3': 'Ù£', '4': 'Ù¤',
            '5': 'Ù¥', '6': 'Ù¦', '7': 'Ù§', '8': 'Ù¨', '9': 'Ù©'
        }

        def convert_text(text: str) -> str:
            """è½¬æ¢æ–‡æœ¬ä¸­çš„æ•°å­—"""

            # è·³è¿‡å ä½ç¬¦ä¸­çš„æ•°å­—
            placeholders = re.findall(r'\{[^}]+\}', text)

            for digit, arabic_digit in arabic_digits.items():
                # åªè½¬æ¢å ä½ç¬¦å¤–çš„æ•°å­—
                text = text.replace(digit, arabic_digit)

            return text

        return self._process_recursive(data, convert_text)
```

**ç¤ºä¾‹**ï¼š
```json
// åŸæ–‡
{
  "text": "Use FLUX.1 model, you have 123 credits"
}

// é˜¿æ‹‰ä¼¯è¯­ï¼ˆæ·»åŠ æ–¹å‘æ ‡è®°å’Œæ•°å­—è½¬æ¢ï¼‰
{
  "text": "Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ â€FLUX.1â€ØŒ Ù„Ø¯ÙŠÙƒ Ù¡Ù¢Ù£ Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯"
}
```

---

### 2.5 ä¼˜åŠ¿åˆ†æ

#### âœ… ä¼˜åŠ¿

1. **æœ¯è¯­ä¸€è‡´æ€§å¼º**
   - æœ¯è¯­è¯å…¸å¼ºåˆ¶ä¿è¯
   - 100% ä¸€è‡´æ€§
   - æ˜“äºç»´æŠ¤å’Œæ‰©å±•

2. **æ ¼å¼ä¿æŠ¤å®Œå–„**
   - æ··åˆæ ¼å¼æ™ºèƒ½åˆ†æ
   - å ä½ç¬¦é›¶ä¸¢å¤±
   - HTML/ç‰¹æ®Šæ ‡è®°ä¿æŠ¤

3. **é«˜æ€§èƒ½**
   - æ‰¹é‡å¤„ç†å‡å°‘ API è°ƒç”¨
   - å¹¶å‘å¤„ç†æé€Ÿ 3-5 å€
   - æ™ºèƒ½ç¼“å­˜é¿å…é‡å¤ç¿»è¯‘

4. **æˆæœ¬ä¼˜åŒ–**
   - ä¸€æ¬¡ç¿»è¯‘å®Œæˆ
   - API è°ƒç”¨å°‘
   - å¢é‡ç¿»è¯‘èŠ‚çœæˆæœ¬

5. **å·¥ç¨‹åŒ–æˆç†Ÿ**
   - å®Œå–„çš„é”™è¯¯å¤„ç†
   - é‡è¯• + é™çº§æœºåˆ¶
   - æ–­ç‚¹ç»­ä¼ æ”¯æŒ

6. **ä¸“ä¸šåŒ–å¤„ç†**
   - RTL è¯­è¨€ç‰¹æ®Šå¤„ç†
   - æ’ç‰ˆè§„èŒƒåŒ–
   - ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æ‰¹

7. **æ˜“äºé›†æˆ**
   - CLI å·¥å…·
   - é…ç½®æ–‡ä»¶é©±åŠ¨
   - äº¤äº’å¼ç•Œé¢

---

#### âŒ åŠ£åŠ¿

1. **ç¿»è¯‘è´¨é‡å¤©èŠ±æ¿**
   - å•è½®ç¿»è¯‘ï¼Œæ— åæ€
   - ä¾èµ– prompt è´¨é‡
   - å¯èƒ½ä¸å¦‚äººå·¥æ¶¦è‰²

2. **æ–‡åŒ–é€‚é…æœ‰é™**
   - è™½ç„¶æœ‰æ’ç‰ˆè§„èŒƒ
   - ä½†æ— æ·±åº¦æ–‡åŒ–å®¡è§†
   - è¯­è¨€è‡ªç„¶åº¦å¯èƒ½ä¸åŠåæ€æœºåˆ¶

3. **çµæ´»æ€§ç•¥ä½**
   - éœ€è¦é¢„å®šä¹‰æœ¯è¯­è¡¨
   - æ–°æœ¯è¯­éœ€æ‰‹åŠ¨æ·»åŠ 
   - ä¸èƒ½è‡ªé€‚åº”å­¦ä¹ 

---

### 2.6 é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**ï¼š
- JSON å›½é™…åŒ–æ–‡ä»¶ç¿»è¯‘
- å¤§è§„æ¨¡æ‰¹é‡ç¿»è¯‘
- éœ€è¦æœ¯è¯­å¼ºä¸€è‡´æ€§çš„åœºæ™¯
- UI/UX æ–‡æ¡ˆç¿»è¯‘
- é¢„ç®—æœ‰é™çš„é¡¹ç›®
- éœ€è¦é«˜æ€§èƒ½çš„åœºæ™¯

âŒ **ä¸é€‚åˆ**ï¼š
- é«˜ç«¯æ–‡å­¦ç¿»è¯‘
- è¥é”€åˆ›æ„æ–‡æ¡ˆï¼ˆéœ€è¦å¤šè½®æ‰“ç£¨ï¼‰
- æ²¡æœ‰æœ¯è¯­ç®¡ç†éœ€æ±‚çš„åœºæ™¯

---

## 3. ä¸¤ç§æ–¹æ¡ˆå¯¹æ¯”

### 3.1 æ ¸å¿ƒå¯¹æ¯”è¡¨

| ç»´åº¦ | **Andrew Ng Translation Agent** | **HiFlux Translation Tool** |
|------|--------------------------------|----------------------------|
| **æ ¸å¿ƒç†å¿µ** | Agentic Workflow + Reflection | Batch + Concurrency + Terminology |
| **ç¿»è¯‘æµç¨‹** | ä¸‰æ­¥å¾ªç¯ï¼ˆåˆè¯‘â†’åæ€â†’æ”¹è¿›ï¼‰ | ä¸€æ¬¡ç¿»è¯‘ï¼ˆæ‰¹é‡ï¼‰ |
| **è´¨é‡ä¿è¯** | LLM è‡ªæˆ‘åæ€ | æœ¯è¯­è¯å…¸ + æ ¼å¼éªŒè¯ |
| **æœ¯è¯­ä¸€è‡´æ€§** | âš ï¸ ä¾èµ– LLMï¼ˆä¸ä¿è¯ï¼‰ | âœ… å¼ºåˆ¶ä¿è¯ï¼ˆ100%ï¼‰ |
| **æ ¼å¼ä¿æŠ¤** | âš ï¸ æ— ç‰¹æ®Šå¤„ç† | âœ… æ™ºèƒ½åˆ†æ + éªŒè¯ |
| **ç¿»è¯‘è´¨é‡** | â­â­â­â­â­ é«˜ï¼ˆå¤šè½®ä¼˜åŒ–ï¼‰ | â­â­â­â­ è‰¯å¥½ï¼ˆå•è½®ï¼‰ |
| **API è°ƒç”¨** | âŒ 3 å€ï¼ˆåˆè¯‘+åæ€+æ”¹è¿›ï¼‰ | âœ… 1 å€ï¼ˆæ‰¹é‡ï¼‰ |
| **é€Ÿåº¦** | âŒ æ…¢ï¼ˆ3 å€è€—æ—¶ï¼‰ | âœ… å¿«ï¼ˆå¹¶å‘ï¼‰ |
| **æˆæœ¬** | âŒ é«˜ï¼ˆ3 å€ï¼‰ | âœ… ä½ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰ |
| **å¹¶å‘èƒ½åŠ›** | âŒ æ— ï¼ˆåŒæ­¥ï¼‰ | âœ… æœ‰ï¼ˆasyncioï¼‰ |
| **å¢é‡ç¿»è¯‘** | âŒ æ—  | âœ… æœ‰ï¼ˆç¼“å­˜ + å¯¹æ¯”ï¼‰ |
| **é”™è¯¯å¤„ç†** | âš ï¸ åŸºç¡€ | âœ… å®Œå–„ï¼ˆé‡è¯•+é™çº§ï¼‰ |
| **RTL æ”¯æŒ** | âš ï¸ ä¾èµ– LLM | âœ… ä¸“é—¨å¤„ç† |
| **é…ç½®åŒ–** | âŒ ç¡¬ç¼–ç  | âœ… é…ç½®æ–‡ä»¶ |
| **é€‚ç”¨åœºæ™¯** | é«˜è´¨é‡æ–‡æ¡£ã€è¥é”€æ–‡æ¡ˆ | JSON å›½é™…åŒ–ã€UI æ–‡æ¡ˆ |

---

### 3.2 è¯¦ç»†å¯¹æ¯”

#### å¯¹æ¯” 1: æœ¯è¯­ä¸€è‡´æ€§

**Andrew Ng æ–¹æ¡ˆ**ï¼š
```
ä¾èµ– LLM è‡ªè¡Œç†è§£æœ¯è¯­
âŒ é—®é¢˜ï¼š
  - åŒä¸€æœ¯è¯­å¯èƒ½ç¿»è¯‘ä¸ä¸€è‡´
  - æ— æ³•å¼ºåˆ¶ä¿è¯
  - ä¾èµ– prompt è´¨é‡

ç¤ºä¾‹ï¼š
  "credits" å¯èƒ½è¢«ç¿»è¯‘ä¸ºï¼š
    - "ç‚¹æ•°"ï¼ˆæŸäº›åœ°æ–¹ï¼‰
    - "ç§¯åˆ†"ï¼ˆå…¶ä»–åœ°æ–¹ï¼‰
    - "ä¿¡ç”¨é¢åº¦"ï¼ˆè¿˜æœ‰åœ°æ–¹ï¼‰
  âŒ ä¸ä¸€è‡´ï¼
```

**HiFlux æ–¹æ¡ˆ**ï¼š
```
æœ¯è¯­è¯å…¸å¼ºåˆ¶æ˜ å°„
âœ… ä¿è¯ï¼š
  - "credits" â†’ "ç‚¹æ•°"ï¼ˆ100% ä¸€è‡´ï¼‰
  - è¯å…¸å¯ç»´æŠ¤
  - å¯æ‰©å±•

ç¤ºä¾‹ï¼š
  terminology.json:
    "credits": "ç‚¹æ•°"

  Prompt æ³¨å…¥:
    "ğŸ“ REQUIRED TRANSLATIONS: 'credits' â†’ 'ç‚¹æ•°'"

  éªŒè¯:
    æ£€æŸ¥æ‰€æœ‰ "credits" æ˜¯å¦éƒ½ç¿»è¯‘ä¸º "ç‚¹æ•°"
```

**ç»“è®º**: HiFlux æ–¹æ¡ˆåœ¨æœ¯è¯­ä¸€è‡´æ€§ä¸Šæœ‰ç»å¯¹ä¼˜åŠ¿ã€‚

---

#### å¯¹æ¯” 2: æ ¼å¼ä¿æŠ¤

**Andrew Ng æ–¹æ¡ˆ**ï¼š
```
æ— ç‰¹æ®Šæ ¼å¼ä¿æŠ¤
âŒ é—®é¢˜ï¼š
  - å ä½ç¬¦å¯èƒ½ä¸¢å¤±ï¼š"{count}" â†’ ""
  - å ä½ç¬¦å¯èƒ½è¢«ç¿»è¯‘ï¼š"{credits}" â†’ "{ç‚¹æ•°}"
  - HTML æ ‡ç­¾å¯èƒ½æŸå

ç¤ºä¾‹ï¼š
  åŸæ–‡: "You have {count} credits"
  ç¿»è¯‘: "æ‚¨æœ‰ ä¸ªç‚¹æ•°"  âŒ å ä½ç¬¦ä¸¢å¤±
```

**HiFlux æ–¹æ¡ˆ**ï¼š
```
æ™ºèƒ½æ ¼å¼åˆ†æ + éªŒè¯
âœ… ä¿è¯ï¼š
  - æ··åˆæ ¼å¼æ™ºèƒ½åˆ†æ
  - å ä½ç¬¦å†…å®¹ä¸ç¿»è¯‘
  - å ä½ç¬¦å¤–å†…å®¹ç¿»è¯‘
  - è‡ªåŠ¨éªŒè¯

ç¤ºä¾‹ï¼š
  åŸæ–‡: "{credits} credits {label}"

  åˆ†æ:
    - å ä½ç¬¦: {credits}, {label}
    - å ä½ç¬¦å¤–: "credits"

  ç¿»è¯‘: "{credits} ç‚¹æ•° {label}"  âœ… æ­£ç¡®

  éªŒè¯:
    âœ… å ä½ç¬¦å®Œæ•´: 2/2
```

**ç»“è®º**: HiFlux æ–¹æ¡ˆåœ¨æ ¼å¼ä¿æŠ¤ä¸Šæœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

---

#### å¯¹æ¯” 3: ç¿»è¯‘è´¨é‡

**Andrew Ng æ–¹æ¡ˆ**ï¼š
```
åæ€æœºåˆ¶å¤šè½®ä¼˜åŒ–
âœ… ä¼˜åŠ¿ï¼š
  - åˆè¯‘ â†’ åæ€ â†’ æ”¹è¿›
  - LLM è‡ªæˆ‘æ‰¹è¯„
  - 4 ç»´åº¦ä¼˜åŒ–ï¼ˆå‡†ç¡®ã€æµç•…ã€é£æ ¼ã€æœ¯è¯­ï¼‰

ç¤ºä¾‹ï¼š
  åŸæ–‡: "Unleash your creativity with AI"

  åˆè¯‘: "ä½¿ç”¨ AI é‡Šæ”¾æ‚¨çš„åˆ›é€ åŠ›"

  åæ€:
    - "é‡Šæ”¾"è¿‡äºç”Ÿç¡¬
    - è¯­åºä¸è‡ªç„¶
    - ç¼ºä¹æ„ŸæŸ“åŠ›

  æ”¹è¿›: "ç”¨ AI æ¿€å‘æ— é™åˆ›é€ åŠ›"

  âœ… æ›´è‡ªç„¶ã€æ›´æœ‰å¸å¼•åŠ›
```

**HiFlux æ–¹æ¡ˆ**ï¼š
```
å•è½®ç¿»è¯‘ + Prompt ä¼˜åŒ–
âš ï¸ é™åˆ¶ï¼š
  - æ— åæ€æœºåˆ¶
  - ä¾èµ– prompt è´¨é‡
  - é€‚åˆ UI æ–‡æ¡ˆ

ç¤ºä¾‹ï¼š
  åŸæ–‡: "Unleash your creativity with AI"

  ç¿»è¯‘: "ä½¿ç”¨ AI é‡Šæ”¾æ‚¨çš„åˆ›é€ åŠ›"

  âš ï¸ å¯èƒ½ç•¥æ˜¾ç”Ÿç¡¬
```

**ç»“è®º**: Andrew Ng æ–¹æ¡ˆåœ¨ç¿»è¯‘è´¨é‡ä¸Šæœ‰ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯è¥é”€æ–‡æ¡ˆã€‚

---

#### å¯¹æ¯” 4: æ€§èƒ½ä¸æˆæœ¬

**Andrew Ng æ–¹æ¡ˆ**ï¼š
```
3 å€è°ƒç”¨ï¼Œ3 å€è€—æ—¶
âŒ æˆæœ¬ï¼š
  - åˆè¯‘: 1 æ¬¡ API è°ƒç”¨
  - åæ€: 1 æ¬¡ API è°ƒç”¨
  - æ”¹è¿›: 1 æ¬¡ API è°ƒç”¨
  - æ€»è®¡: 3 æ¬¡

âŒ è€—æ—¶ï¼š
  - å‡è®¾å•æ¬¡ 2 ç§’
  - æ€»è®¡: 6 ç§’

  500 æ–‡æœ¬:
    - 3000 æ¬¡è°ƒç”¨
    - çº¦ 50 åˆ†é’Ÿ
    - æˆæœ¬é«˜
```

**HiFlux æ–¹æ¡ˆ**ï¼š
```
æ‰¹é‡å¹¶å‘ï¼Œ1 å€è°ƒç”¨
âœ… æˆæœ¬ï¼š
  - æ‰¹é‡: 20 ä¸ªæ–‡æœ¬/æ‰¹æ¬¡
  - 500 æ–‡æœ¬ = 25 æ‰¹æ¬¡
  - æ€»è®¡: 25 æ¬¡è°ƒç”¨ï¼ˆèŠ‚çœ 99%ï¼‰

âœ… è€—æ—¶ï¼š
  - å¹¶å‘: 3 ä¸ªæ‰¹æ¬¡åŒæ—¶å¤„ç†
  - 25 æ‰¹æ¬¡ / 3 = çº¦ 9 è½®
  - å‡è®¾æ¯æ‰¹æ¬¡ 3 ç§’
  - æ€»è®¡: 27 ç§’ï¼ˆæé€Ÿ 100 å€ï¼‰

  500 æ–‡æœ¬:
    - 25 æ¬¡è°ƒç”¨
    - çº¦ 3-5 åˆ†é’Ÿ
    - æˆæœ¬ä½
```

**ç»“è®º**: HiFlux æ–¹æ¡ˆåœ¨æ€§èƒ½å’Œæˆæœ¬ä¸Šæœ‰å‹å€’æ€§ä¼˜åŠ¿ã€‚

---

#### å¯¹æ¯” 5: é•¿æ–‡æœ¬å¤„ç†

**Andrew Ng æ–¹æ¡ˆ**ï¼š
```
æ™ºèƒ½åˆ†å— + ä¸Šä¸‹æ–‡ä¿æŒ
âœ… ä¼˜åŠ¿ï¼š
  - åˆ†å—ç®—æ³•ä¼˜åŒ–
  - æä¾›å®Œæ•´ä¸Šä¸‹æ–‡
  - ç¿»è¯‘è¿è´¯

ç¤ºä¾‹ï¼š
  æ–‡æœ¬åˆ†ä¸º [A, B, C]

  ç¿»è¯‘ B æ—¶:
    ä¸Šä¸‹æ–‡: A <TRANSLATE_THIS>B</TRANSLATE_THIS> C

  âœ… B çš„ç¿»è¯‘è€ƒè™‘äº† A å’Œ C çš„ä¸Šä¸‹æ–‡
```

**HiFlux æ–¹æ¡ˆ**ï¼š
```
æŒ‰ JSON ç»“æ„åˆ†å—
âš ï¸ é™åˆ¶ï¼š
  - æŒ‰ JSON key åˆ†å—
  - è·¨ key çš„ä¸Šä¸‹æ–‡å¯èƒ½ä¸¢å¤±
  - é€‚åˆç‹¬ç«‹çš„æ–‡æ¡ˆæ¡ç›®

ç¤ºä¾‹ï¼š
  JSON:
    {
      "title": "æ–‡æœ¬ A",
      "description": "æ–‡æœ¬ B"
    }

  ç¿»è¯‘æ—¶:
    - title å’Œ description ç‹¬ç«‹ç¿»è¯‘
    - âš ï¸ æ— è·¨ key ä¸Šä¸‹æ–‡
```

**ç»“è®º**: Andrew Ng æ–¹æ¡ˆåœ¨é•¿æ–‡æœ¬è¿è´¯æ€§ä¸Šæ›´å¥½ã€‚

---

### 3.3 åœºæ™¯é€‰æ‹©æŒ‡å—

#### åœºæ™¯ 1: JSON å›½é™…åŒ–ï¼ˆUI æ–‡æ¡ˆï¼‰

**ç‰¹ç‚¹**ï¼š
- æ•°ç™¾ä¸ªçŸ­æ–‡æ¡ˆ
- æœ¯è¯­ä¸€è‡´æ€§è¦æ±‚é«˜
- æ ¼å¼ä¿æŠ¤è¦æ±‚é«˜ï¼ˆå ä½ç¬¦ï¼‰
- é¢„ç®—æœ‰é™

**æ¨è**: âœ… HiFlux æ–¹æ¡ˆ

**ç†ç”±**ï¼š
- æœ¯è¯­å¼ºåˆ¶ä¿è¯
- æ ¼å¼é›¶æŸå
- æˆæœ¬ä½ï¼Œé€Ÿåº¦å¿«
- å¢é‡ç¿»è¯‘æ”¯æŒ

---

#### åœºæ™¯ 2: è¥é”€æ–‡æ¡ˆï¼ˆLanding Pageï¼‰

**ç‰¹ç‚¹**ï¼š
- é•¿æ–‡æ¡ˆï¼Œéœ€è¦æ¶¦è‰²
- æ–‡åŒ–é€‚é…è¦æ±‚é«˜
- è¯­è¨€è‡ªç„¶åº¦è¦æ±‚é«˜
- é¢„ç®—å……è¶³

**æ¨è**: âœ… Andrew Ng æ–¹æ¡ˆ

**ç†ç”±**ï¼š
- åæ€æœºåˆ¶ä¼˜åŒ–è´¨é‡
- å¤šè½®æ‰“ç£¨æ›´è‡ªç„¶
- åœ°åŒºæ–¹è¨€æ”¯æŒ
- é€‚åˆé«˜ä»·å€¼å†…å®¹

---

#### åœºæ™¯ 3: æŠ€æœ¯æ–‡æ¡£

**ç‰¹ç‚¹**ï¼š
- é•¿æ–‡æ¡£ï¼Œç« èŠ‚å¤š
- æœ¯è¯­ä¸“ä¸šï¼Œéœ€ä¸€è‡´
- ä¸Šä¸‹æ–‡è¿è´¯è¦æ±‚é«˜
- é¢„ç®—ä¸­ç­‰

**æ¨è**: âœ… Andrew Ng æ–¹æ¡ˆï¼ˆæˆ–æ··åˆæ–¹æ¡ˆï¼‰

**ç†ç”±**ï¼š
- åˆ†å—ç®—æ³•å¤„ç†é•¿æ–‡æœ¬
- ä¸Šä¸‹æ–‡ä¿æŒè¿è´¯æ€§
- åæ€æå‡ä¸“ä¸šåº¦

**æ··åˆæ–¹æ¡ˆ**ï¼š
- æœ¯è¯­ç®¡ç†ç”¨ HiFlux æ–¹æ³•
- ç¿»è¯‘æµç¨‹ç”¨ Andrew Ng æ–¹æ³•

---

#### åœºæ™¯ 4: å¤§è§„æ¨¡æ‰¹é‡ç¿»è¯‘

**ç‰¹ç‚¹**ï¼š
- æ•°åƒæ¡æ–‡æœ¬
- æ—¶é—´è¦æ±‚ç´§
- é¢„ç®—æœ‰é™
- æœ¯è¯­å¤š

**æ¨è**: âœ… HiFlux æ–¹æ¡ˆ

**ç†ç”±**ï¼š
- æ‰¹é‡å¹¶å‘æ•ˆç‡é«˜
- æˆæœ¬æ§åˆ¶å¥½
- æœ¯è¯­ç®¡ç†å®Œå–„
- å¢é‡ç¿»è¯‘å‡å°‘å·¥ä½œé‡

---

## 4. æŠ€æœ¯é€‰å‹å»ºè®®

### 4.1 æ–°é¡¹ç›®å»ºè®®ï¼šæ··åˆæ–¹æ¡ˆ

ç»“åˆä¸¤ç§æ–¹æ¡ˆçš„ä¼˜åŠ¿ï¼Œæ„å»ºæ··åˆç¿»è¯‘ç³»ç»Ÿï¼š

```python
class HybridTranslator:
    """æ··åˆç¿»è¯‘å™¨"""

    def __init__(self):
        self.terminology_mgr = TerminologyManager()  # HiFlux æœ¯è¯­ç®¡ç†
        self.batch_translator = BatchTranslator()     # HiFlux æ‰¹é‡ç¿»è¯‘
        self.reflection_translator = ReflectionTranslator()  # Andrew Ng åæ€

    def translate(self, source_data: Dict, target_lang: str, mode: str = 'smart'):
        """
        æ··åˆç¿»è¯‘

        mode:
          - 'fast': å…¨éƒ¨ä½¿ç”¨æ‰¹é‡ç¿»è¯‘
          - 'quality': å…¨éƒ¨ä½¿ç”¨åæ€æœºåˆ¶
          - 'smart': æ™ºèƒ½é€‰æ‹©ï¼ˆæ¨èï¼‰
        """

        # 1. æå–å¯ç¿»è¯‘å†…å®¹ï¼ˆHiFlux æ–¹æ³•ï¼‰
        items = self.extract_translatable_items(source_data)

        # 2. åˆ†ç±»ï¼šå“ªäº›ç”¨å¿«é€Ÿï¼Œå“ªäº›ç”¨é«˜è´¨é‡
        if mode == 'smart':
            fast_items, quality_items = self.classify_items(items)
        elif mode == 'fast':
            fast_items, quality_items = items, []
        else:  # 'quality'
            fast_items, quality_items = [], items

        # 3. å¹¶è¡Œå¤„ç†ä¸¤ç§ç±»å‹
        results = {}

        # å¿«é€Ÿç¿»è¯‘ï¼ˆæ‰¹é‡å¹¶å‘ï¼‰
        if fast_items:
            fast_results = await self.batch_translator.translate(
                fast_items, target_lang, self.terminology_mgr
            )
            results.update(fast_results)

        # é«˜è´¨é‡ç¿»è¯‘ï¼ˆåæ€æœºåˆ¶ï¼‰
        if quality_items:
            quality_results = await self.reflection_translator.translate(
                quality_items, target_lang, self.terminology_mgr
            )
            results.update(quality_results)

        # 4. é‡å»º JSON
        translated_data = self.rebuild_json(source_data, results)

        return translated_data

    def classify_items(self, items: List[Dict]) -> Tuple[List, List]:
        """
        æ™ºèƒ½åˆ†ç±»ï¼šå“ªäº›ç”¨å¿«é€Ÿï¼Œå“ªäº›ç”¨é«˜è´¨é‡

        é«˜è´¨é‡æ¨¡å¼çš„åˆ¤æ–­æ¡ä»¶ï¼š
          - key åŒ…å«å…³é”®è¯: hero, landing, marketing, tagline, slogan
          - æ–‡æœ¬é•¿åº¦ > 30 è¯
          - ä¸Šä¸‹æ–‡ç±»å‹ä¸º 'marketing'
        """

        fast_items = []
        quality_items = []

        quality_keywords = ['hero', 'landing', 'marketing', 'tagline', 'slogan', 'about']

        for item in items:
            path = item['path']
            text = item['text']
            context = item.get('context', '')

            # åˆ¤æ–­é€»è¾‘
            is_quality = (
                any(keyword in path.lower() for keyword in quality_keywords) or
                len(text.split()) > 30 or
                context == 'marketing'
            )

            if is_quality:
                quality_items.append(item)
            else:
                fast_items.append(item)

        return fast_items, quality_items
```

---

### 4.2 æ ¸å¿ƒåŠŸèƒ½æ¨¡å—è®¾è®¡

#### æ¨¡å— 1: æœ¯è¯­ç®¡ç†ï¼ˆHiFlux æ–¹æ³•ï¼‰

```python
class TerminologyManager:
    """æœ¯è¯­ä¸€è‡´æ€§ç®¡ç†å™¨"""

    - load_terminology_rules()          # åŠ è½½æœ¯è¯­é…ç½®
    - extract_terms_from_text()         # æå–æœ¯è¯­
    - get_term_translation()            # è·å–æœ¯è¯­ç¿»è¯‘
    - build_term_dictionary_for_prompt() # æ„å»º Prompt æœ¯è¯­è¯å…¸
    - validate_term_consistency()       # éªŒè¯æœ¯è¯­ä¸€è‡´æ€§
```

**å…³é”®ç‚¹**ï¼š
- âœ… ä¿ç•™æœ¯è¯­ï¼ˆpreserve_termsï¼‰
- âœ… ä¸€è‡´æ€§æœ¯è¯­ï¼ˆconsistent_termsï¼‰
- âœ… Prompt æ³¨å…¥
- âœ… éªŒè¯æœºåˆ¶

---

#### æ¨¡å— 2: æ ¼å¼ä¿æŠ¤ï¼ˆHiFlux æ–¹æ³•ï¼‰

```python
class FormatProtector:
    """æ ¼å¼ä¿æŠ¤å™¨"""

    - analyze_mixed_format()        # åˆ†ææ··åˆæ ¼å¼
    - extract_placeholders()        # æå–å ä½ç¬¦
    - extract_html_tags()           # æå– HTML æ ‡ç­¾
    - validate_format_integrity()   # éªŒè¯æ ¼å¼å®Œæ•´æ€§
```

**å…³é”®ç‚¹**ï¼š
- âœ… å ä½ç¬¦è¯†åˆ«
- âœ… æ··åˆæ ¼å¼åˆ†æ
- âœ… æ ¼å¼éªŒè¯

---

#### æ¨¡å— 3: å¿«é€Ÿç¿»è¯‘ï¼ˆHiFlux æ–¹æ³•ï¼‰

```python
class BatchTranslator:
    """æ‰¹é‡ç¿»è¯‘å™¨"""

    - create_batches()              # åˆ›å»ºæ™ºèƒ½æ‰¹æ¬¡
    - translate_batch()             # æ‰¹é‡ç¿»è¯‘ï¼ˆå¹¶å‘ï¼‰
    - retry_with_backoff()          # é‡è¯•æœºåˆ¶
    - fallback_to_single()          # é™çº§å¤„ç†
```

**å…³é”®ç‚¹**ï¼š
- âœ… æ‰¹é‡å¤„ç†
- âœ… å¹¶å‘æ‰§è¡Œ
- âœ… é”™è¯¯å¤„ç†

---

#### æ¨¡å— 4: é«˜è´¨é‡ç¿»è¯‘ï¼ˆAndrew Ng æ–¹æ³•ï¼‰

```python
class ReflectionTranslator:
    """åæ€ç¿»è¯‘å™¨"""

    - initial_translation()         # åˆå§‹ç¿»è¯‘
    - reflect_on_translation()      # åæ€è¯„ä»·
    - improve_translation()         # æ”¹è¿›ç¿»è¯‘
    - translate_with_reflection()   # å®Œæ•´æµç¨‹
```

**å…³é”®ç‚¹**ï¼š
- âœ… ä¸‰æ­¥å¾ªç¯
- âœ… è‡ªæˆ‘æ‰¹è¯„
- âœ… è¿­ä»£ä¼˜åŒ–

---

#### æ¨¡å— 5: åå¤„ç†ï¼ˆHiFlux æ–¹æ³•ï¼‰

```python
class PostProcessor:
    """åå¤„ç†å™¨"""

    - apply_typography_rules()      # æ’ç‰ˆè§„èŒƒåŒ–
    - process_rtl_languages()       # RTL è¯­è¨€å¤„ç†
    - add_direction_marks()         # æ·»åŠ æ–¹å‘æ ‡è®°
    - convert_numbers()             # æ•°å­—è½¬æ¢
```

**å…³é”®ç‚¹**ï¼š
- âœ… æ’ç‰ˆä¼˜åŒ–
- âœ… RTL æ”¯æŒ
- âœ… æœ¬åœ°åŒ–å¤„ç†

---

### 4.3 å®ç°è·¯çº¿å›¾

#### Phase 1: MVPï¼ˆåŸºäº HiFlux æ–¹æ¡ˆï¼‰

**åŠŸèƒ½**ï¼š
- âœ… æœ¯è¯­ç®¡ç†
- âœ… æ ¼å¼ä¿æŠ¤
- âœ… æ‰¹é‡ç¿»è¯‘
- âœ… åŸºç¡€éªŒè¯

**æ—¶é—´**: 2-3 å‘¨

---

#### Phase 2: å¢å¼ºåŠŸèƒ½

**åŠŸèƒ½**ï¼š
- âœ… å¢é‡ç¿»è¯‘
- âœ… é€‰æ‹©æ€§ç¿»è¯‘
- âœ… RTL ä¼˜åŒ–
- âœ… å®Œå–„é”™è¯¯å¤„ç†

**æ—¶é—´**: 2-3 å‘¨

---

#### Phase 3: é«˜è´¨é‡æ¨¡å¼ï¼ˆå¼•å…¥ Andrew Ng æ–¹æ³•ï¼‰

**åŠŸèƒ½**ï¼š
- âœ… åæ€æœºåˆ¶
- âœ… æ™ºèƒ½æ¨¡å¼ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
- âœ… æ··åˆç¿»è¯‘

**æ—¶é—´**: 3-4 å‘¨

---

#### Phase 4: ç”Ÿäº§å°±ç»ª

**åŠŸèƒ½**ï¼š
- âœ… å®Œæ•´æµ‹è¯•
- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… æ–‡æ¡£å®Œå–„
- âœ… CI/CD

**æ—¶é—´**: 4-6 å‘¨

---

## 5. æ€»ç»“

### å…³é”®æ´å¯Ÿ

1. **Andrew Ng æ–¹æ¡ˆçš„æ ¸å¿ƒä»·å€¼**ï¼š
   - âœ… åæ€æœºåˆ¶æå‡ç¿»è¯‘è´¨é‡
   - âœ… é€‚åˆé«˜ä»·å€¼å†…å®¹
   - âŒ ä½†æˆæœ¬é«˜ã€é€Ÿåº¦æ…¢

2. **HiFlux æ–¹æ¡ˆçš„æ ¸å¿ƒä»·å€¼**ï¼š
   - âœ… æœ¯è¯­å¼ºä¸€è‡´æ€§
   - âœ… æ ¼å¼é›¶æŸå
   - âœ… é«˜æ€§èƒ½ã€ä½æˆæœ¬
   - âŒ ä½†è´¨é‡å¤©èŠ±æ¿æœ‰é™

3. **æœ€ä½³å®è·µ**ï¼š
   - âœ… æ··åˆæ–¹æ¡ˆï¼šå–é•¿è¡¥çŸ­
   - âœ… æ™ºèƒ½æ¨¡å¼ï¼šè‡ªåŠ¨é€‰æ‹©
   - âœ… æ¨¡å—åŒ–è®¾è®¡ï¼šçµæ´»ç»„åˆ

---

### æœ€ç»ˆå»ºè®®

é’ˆå¯¹ **JSON å›½é™…åŒ–ç¿»è¯‘å·¥å…·** é¡¹ç›®ï¼š

1. **ä¼˜å…ˆé‡‡ç”¨ HiFlux æ–¹æ¡ˆä½œä¸ºåŸºç¡€**
   - æœ¯è¯­ç®¡ç†
   - æ ¼å¼ä¿æŠ¤
   - æ‰¹é‡å¹¶å‘

2. **å¼•å…¥ Andrew Ng çš„åæ€æœºåˆ¶ä½œä¸ºå¯é€‰é¡¹**
   - é«˜è´¨é‡æ¨¡å¼
   - æ™ºèƒ½æ¨¡å¼

3. **é‡ç‚¹å®ç°æ··åˆæ–¹æ¡ˆ**
   - å¹³è¡¡è´¨é‡å’Œæˆæœ¬
   - é€‚åº”ä¸åŒåœºæ™¯

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-01-16
**ä½œè€…**: æŠ€æœ¯å›¢é˜Ÿ
